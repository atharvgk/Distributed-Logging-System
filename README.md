# Distributed Log Management and Alerting System

## Project Overview

In a microservices architecture, effective log management is crucial for operational excellence. This project implements a distributed logging framework that streamlines the collection, storage, and analysis of logs generated by various microservices. It enhances operational visibility, facilitates proactive issue resolution, and supports real-time alerts for critical events.

### Key Features:
- **Centralized Log Management**: Aggregate logs from multiple microservices for efficient storage and querying.
- **Alerting System**: Monitor logs in real-time and generate alerts for critical log levels (e.g., ERROR, FATAL).
- **Heartbeat Mechanism**: Detect node failures by monitoring periodic heartbeat signals.
- **Scalable Design**: Built to handle dynamic and distributed application environments.

---

## System Architecture

### Components:
1. **Microservices**: Nodes that independently generate logs and send heartbeat signals.
2. **Log Accumulator**: Collects logs, formats them, and forwards them to Kafka.
3. **Pub-Sub Model (Kafka)**: Facilitates asynchronous log distribution.
4. **Log Storage (Elasticsearch)**: Indexes and stores logs for efficient querying.
5. **Alerting System**: Listens for critical logs and triggers alerts.
![dls](https://github.com/user-attachments/assets/d5d65f05-2539-4df3-a062-0129bfad4e46)
---

## Tools and Technologies

- **Programming Language**: Python
- **Log Accumulator**: Fluentd
- **Pub-Sub Model**: Apache Kafka
- **Log Storage**: Elasticsearch
- **Visualization**: Kibana

---

## Setup and Configuration

### Prerequisites:
- Two Virtual Machines (VMs) on VirtualBox:
  - **Seed VM (Producer)**: Runs Kafka and Fluentd.
  - **Ubuntu VM (Consumer)**: Hosts Kafka, Elasticsearch, and Kibana.

- **Network Configuration**:
  - Create a new NAT network in VirtualBox to assign different IPs to each VM.
  - Check and note the IPs of both VMs using:
    ```bash
    ip a
    ```
  - Update the code and Fluentd configuration files with the respective IPs.

---

## Installation and Execution

To run this project, follow these steps:

### Step 1: Start Services on the Seed VM (Producer)
Run the following commands to start Kafka and Fluentd:
```bash
sudo systemctl start kafka
sudo systemctl start fluentd
```
### Step 2: Start Services on the Ubuntu VM (Consumer)
Run the following commands to start Kafka ,Elasticsearch and Kibana:
```bash
sudo systemctl start kafka 
sudo systemctl start elasticsearch 
sudo systemctl start kibana
```
### Step 3: Run consumer.py on Seed VM
```bash
python3 consumer.py
```
### Step 4: Run fluentd configuration file
```bash
sudo fluentd -c fluent1.conf
sudo fluentd -c fluent2.conf
sudo fluentd -c fluent3.conf
```
### Step 5: Run all microServices file on Seed VM 
```bash
python3 microServices1.py
python3 microServices2.py
python3 microServices3.py
```
### Step 6: Run alerting_system file on Ubuntu Vm
```bash
python3 alerting_system.py
```
